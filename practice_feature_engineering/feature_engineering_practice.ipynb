{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_df= pd.read_csv('data/turnover.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_df = hr_df.rename(columns={'average_montly_hours':'average_monthly_hours', 'sales': 'role', 'Work_accident':'work_accident'})\n",
    "hr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(hr_df, test_size=0.2, random_state=289, stratify=hr_df.left)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class OutlierRemoval(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def fit(self,X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        for column in self.columns:\n",
    "            q25, q75 = np.percentile(X[[column]], [25,75])\n",
    "            iqr = q75-q25\n",
    "            \n",
    "            X = X[(X[column] <= (q75 + 1.5*iqr)) & (X[column] >= (q25 - 1.5*iqr))]\n",
    "            \n",
    "        return X\n",
    "    \n",
    "outlier_removal = OutlierRemoval(['last_evaluation', 'time_spend_company'])\n",
    "train_set_adv = outlier_removal.fit_transform(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_set.drop('left', axis=1).copy()\n",
    "y = train_set['left'].copy()\n",
    "\n",
    "X_adv = train_set_adv.drop('left', axis=1).copy()\n",
    "y_adv = train_set_adv['left'].copy()\n",
    "\n",
    "X_test = test_set.drop('left', axis=1).copy()\n",
    "y_test = test_set['left'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import KBinsDiscretizer, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "class CustomOrdinalEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, order={}):\n",
    "        self.order = order\n",
    "        \n",
    "    def fit(self,X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        if self.order :\n",
    "            for column in X.columns:\n",
    "                X.loc[:, column] =  X.loc[:, column].replace(list(self.order.keys()), list(self.order.values()))\n",
    "    \n",
    "        return X\n",
    "\n",
    "binning_features = ['satisfaction_level', 'last_evaluation', 'average_monthly_hours']\n",
    "\n",
    "basic_featuring = ColumnTransformer([\n",
    "    ('role_enc', OneHotEncoder(), ['role']),\n",
    "    ('binning', KBinsDiscretizer(n_bins=7, encode='ordinal'), binning_features),\n",
    "    ('scaling', MinMaxScaler(), ['average_monthly_hours']),\n",
    "    ('salary_enc', CustomOrdinalEncoder())\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "basic_featuring = ColumnTransformer([\n",
    "    ('role_basic', OneHotEncoder(), ['role'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "\n",
    "basic_feature_pipeline = Pipeline([\n",
    "    ('basic_salary', CustomOrdinalEncoder('salary', {'low': 1, 'medium': 2, 'high': 3})),\n",
    "    ('basic_role', basic_featuring),\n",
    "    ('basic_scaling', MinMaxScaler())\n",
    "])\n",
    "\n",
    "\n",
    "advanced_featuring = ColumnTransformer([\n",
    "    ('binning', KBinsDiscretizer(n_bins=7, encode='ordinal'), ),\n",
    "    ('role_advanced', OneHotEncoder(), ['role'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "advanced_feature_pipeline = Pipeline([\n",
    "    ('advanced_salary', CustomOrdinalEncoder('salary', {'low':1, 'medium': 2, 'high': 3})),\n",
    "    ('advanced_featuring', advanced_featuring),\n",
    "    ('advanced_scaling', MinMaxScaler()),\n",
    "    ('linear_reg', De1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prepared = basic_feature_pipeline.fit_transform(X)\n",
    "X_test_prepared = basic_feature_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_adv_prepared = advanced_feature_pipeline.fit_transform(X_adv)\n",
    "X_test_adv_prepared = advanced_feature_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering - nonregularized logit, all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, matthews_corrcoef\n",
    "\n",
    "initial_logreg = LogisticRegression(penalty='none', solver='newton-cg')\n",
    "initial_logreg.fit(initial_X, initial_y)\n",
    "\n",
    "initial_y_pred = initial_logreg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, initial_y_pred))\n",
    "print(matthews_corrcoef(y_test, initial_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([*zip(initial_X_test.columns, initial_logreg.coef_[0])], key = lambda pair: abs(pair[1]), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, matthews_corrcoef\n",
    "\n",
    "X = train.drop('left', axis=1)\n",
    "y = train['left']\n",
    "\n",
    "logreg = LogisticRegression(penalty='none', solver='newton-cg')\n",
    "logreg.fit(X, y)\n",
    "\n",
    "X_test = test.drop('left', axis=1)\n",
    "y_test = test['left']\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(matthews_corrcoef(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([*zip(X_test.columns, logreg.coef_[0])], key = lambda pair: abs(pair[1]), reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering - regularized logit, all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, matthews_corrcoef\n",
    "\n",
    "initial_logreg_l1 = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "initial_logreg_l1.fit(initial_X, initial_y)\n",
    "\n",
    "initial_y_pred_l1 = initial_logreg_l1.predict(initial_X_test)\n",
    "\n",
    "print(classification_report(initial_y_test, initial_y_pred_l1))\n",
    "print(matthews_corrcoef(initial_y_test, initial_y_pred_l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([*zip(X_test.columns, initial_logreg_l1.coef_[0])], key = lambda pair: abs(pair[1]), reverse = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
